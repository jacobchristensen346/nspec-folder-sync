{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a95253e4-9e64-4112-ae14-da467fb3404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT SOURCE: C:\\Users\\JChristensen01\\Downloads\\source\\\n",
      "CURRENT DESTINATION: C:\\Users\\JChristensen01\\Downloads\\dest\\\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1231.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1231.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1232.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1232.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1233.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1233.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1234.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1234.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1235.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1235.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1237.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1237.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1238.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1238.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "C:\\Users\\JChristensen01\\Downloads\\source\\6-1239.db -> C:\\Users\\JChristensen01\\Downloads\\dest\\6-1239.db\n",
      "Database file not in correct format, returning empty dataframe\n",
      "Data appending failed with error: name 'df' is not defined\n",
      "8 File(s) copied\n",
      "\n",
      "\n",
      "Elapsed time: 0.353361 seconds\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\dest\\\\placeholder.txt' -> 'C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\dest\\\\2025-11-26_12-36-04.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 196\u001b[0m\n\u001b[0;32m    194\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRR_DEFECTS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m sync_inst \u001b[38;5;241m=\u001b[39m FolderSync(folderpaths, log_path, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 196\u001b[0m sync_inst\u001b[38;5;241m.\u001b[39mperform_sync(\u001b[38;5;28;01mTrue\u001b[39;00m, sql_query, dest_db, table_name)\n",
      "Cell \u001b[1;32mIn[36], line 138\u001b[0m, in \u001b[0;36mFolderSync.perform_sync\u001b[1;34m(self, transfer, sql_query, dest_db, table_name)\u001b[0m\n\u001b[0;32m    136\u001b[0m output_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    137\u001b[0m rename_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(rename_datetime) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 138\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplaceholder.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, rename_log)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults log saved to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m rename_log)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPress Enter to exit...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\dest\\\\placeholder.txt' -> 'C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\dest\\\\2025-11-26_12-36-04.txt'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "--------------\n",
    "folder_sync.py\n",
    "--------------\n",
    "\n",
    "This module is used to initiate synchronization between two separate folders.\n",
    "It uses the Windows 'xcopy' command to perform the sync, so the module\n",
    "must be used in a Windows environment to work properly.\n",
    "\n",
    "Initially, it was coded specifically to perform file sync between the nSpec \n",
    "tool local hard drive and the nSpec shared LAN archive folder.\n",
    "This version has been generalized and can receive user arguments.\n",
    "If ran as a script, the default behavior is to perform the nSpec folder\n",
    "synchronization. Arguments can be passed if imported as a module.\n",
    "\n",
    "Users provide a list of paired directories representing source and destination\n",
    "folders. Any new/modified files in the source folders will be copied to the \n",
    "corresponding destination folders.\n",
    "\n",
    "The sync is one-way only, meaning any changes made directly to the destination\n",
    "folder will not be reflected in the local hard drive.\n",
    "This allows the destination folder to contain all data ever recorded,\n",
    "even when the source folder has been purged.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import shutil\n",
    "import warnings\n",
    "import time\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import create_engine\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "class FolderSync:\n",
    "    \n",
    "    def __init__(self, folderpaths, log_path, skip_verify=False):\n",
    "        \"\"\"Initialize the filepaths variables.\n",
    "        \n",
    "        Args:\n",
    "            filepaths (list): List of paired folderpaths. Expects an input\n",
    "                in the form of '[..., [[src, dest]], ...]', where each\n",
    "                'src' and 'dest' are the source and destination folder\n",
    "                paths, respectively, and are strings.\n",
    "            log_path (str): Represents the folder to save a log file into\n",
    "                recording all files which were synced.\n",
    "            skip_verify (bool, optional): If set to to True, the program\n",
    "                will not ask for user verification via keyboard input\n",
    "                before the filesync is initiated. The default is False.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.list_of_dir = folderpaths\n",
    "        self.log_path = log_path\n",
    "        self.skip_verify = skip_verify\n",
    "        \n",
    "    def perform_sync(self, transfer=False, sql_query=\"\", dest_db=\"\", table_name=\"\"):\n",
    "        \"\"\"Performs the file sync between the source and destination folders.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.skip_verify:\n",
    "            print(\"Please review the source and destination folders...\\n\")\n",
    "            for idx, dir in enumerate(self.list_of_dir):\n",
    "                print(\"SOURCE \" + str(idx + 1) + \": \" + dir[0])\n",
    "                print(\"DESTINATION \" + str(idx + 1) + \": \" + dir[1])\n",
    "            usrcon = input(\"\\nType 'Yes' and press Enter \"\n",
    "                           + \"to confirm initiation of folder sync: \")\n",
    "            if usrcon == \"Yes\":\n",
    "                print(\"\\nProceeding with the folder sync...\\n\")\n",
    "            else:\n",
    "                print(\"\\nAborting the folder sync!\")\n",
    "                return\n",
    "            \n",
    "        start = time.perf_counter()  # Track total time elapsed\n",
    "        \n",
    "        # Create a text file to capture log output.\n",
    "        output_file = open(self.log_path + \"placeholder.txt\", \"w\")\n",
    "        \n",
    "        # Iterate through each source and destination.\n",
    "        for dir in self.list_of_dir:\n",
    "        \n",
    "            print(\"CURRENT SOURCE: \" + dir[0])\n",
    "            print(\"CURRENT DESTINATION: \" + dir[1])\n",
    "        \n",
    "            # Create the sync process using the xcopy command.\n",
    "            process = subprocess.Popen(\n",
    "                [\"xcopy\", dir[0], dir[1], \"/f\", \"/e\", \"/d\", \"/c\", \"/y\"], \n",
    "                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                shell = True, text = True)\n",
    "        \n",
    "            # List current source and destination in log file.\n",
    "            output_file.write(\"CURRENT SOURCE: \" + dir[0] + \"\\n\")\n",
    "            output_file.write(\"CURRENT DESTINATION: \" + dir[1] + \"\\n\")\n",
    "  \n",
    "            # Stream the sync output in real-time.\n",
    "            for line in process.stdout:\n",
    "                print(line, end=\"\")\n",
    "                output_file.write(line)  # Write each line to text file\n",
    "                if transfer == True and line[-4:-1] == \".db\":\n",
    "                    mod_db = re.search(r\"->\\s(.*)$\", line[0:-1]).group(1)\n",
    "                    fetched_data = DbInterface(mod_db).fetch_from(sql_query)\n",
    "                    DbInterface(dest_db).append_to(fetched_data, table_name)\n",
    "                    \n",
    "            output_file.write(\"\\n\")\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        end = time.perf_counter()  # Track total time elapsed\n",
    "        \n",
    "        print(f\"Elapsed time: {end - start:.6f} seconds\")\n",
    "        output_file.write(f\"Elapsed time: {end - start:.6f} seconds\\n\")\n",
    "        \n",
    "        # Get the date and time when sync was performed.\n",
    "        current_datetime = ((datetime.now()).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        rename_datetime = current_datetime.replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "        output_file.write(\"Sync finished --> \" + current_datetime + \"\\n\")\n",
    "        \n",
    "        # Rename text file to current date and time.\n",
    "        output_file.close()\n",
    "        rename_log = self.log_path + str(rename_datetime) + \".txt\"\n",
    "        os.replace(self.log_path + \"placeholder.txt\", rename_log)\n",
    "        \n",
    "        print(\"Results log saved to \" + rename_log)\n",
    "        \n",
    "        input(\"Press Enter to exit...\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # List of all source and destination paths to perform copying.\n",
    "    # This is specifically for the nSpec local folders -> LAN folders.\n",
    "    folderpaths = [\n",
    "        [\"C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\source\\\\\",\n",
    "         \"C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\dest\\\\\"]]\n",
    "    # The location for saving the log file.\n",
    "    log_path = \"C:\\\\Users\\\\JChristensen01\\\\Downloads\\\\dest\\\\\"\n",
    "    sql_query = text(\"\"\"\n",
    "    SELECT vwDefects.DefectID, \n",
    "           vwDefects.ImageID, \n",
    "           vwDefects.AnalysisID, \n",
    "           vwDefects.DeviceID, \n",
    "           vwDefects.X, \n",
    "           vwDefects.Y, \n",
    "           vwDefects.W, \n",
    "           vwDefects.H, \n",
    "           vwDefects.Area, \n",
    "           vwDefects.Intensity, \n",
    "           vwDefects.IntensityDeviation, \n",
    "           vwDefects.Eccentricity, \n",
    "           vwDefects.Orientation, \n",
    "           vwDefects.XinDevice, \n",
    "           vwDefects.YinDevice, \n",
    "           vwDefects.ClassID, \n",
    "           vwDefects.Score, \n",
    "           vwDefects.Contour, \n",
    "           vwDefects.ClassName, \n",
    "           ParameterGroups.Name, \n",
    "           SPA.PropertyData AS SampleID,\n",
    "           SPB.PropertyData AS JobName\n",
    "       \n",
    "      FROM vwDefects \n",
    "           INNER JOIN Analysis \n",
    "           ON vwDefects.AnalysisID = Analysis.AnalysisID \n",
    "       \n",
    "           INNER JOIN ScanProperties SPA \n",
    "           ON Analysis.ScanID = SPA.ScanID \n",
    "       \n",
    "           INNER JOIN ScanProperties SPB \n",
    "           ON Analysis.ScanID = SPB.ScanID\n",
    "       \n",
    "           INNER JOIN ParameterGroups \n",
    "           ON Analysis.ParameterGroupGUID = ParameterGroups.GroupGUID \n",
    "       \n",
    "     WHERE ParameterGroups.Name = '5XBF_BareWaferPRR' \n",
    "       AND SPA.PropertyName = 'SampleID'\n",
    "       AND SPB.PropertyName = 'JobName'\n",
    "    \"\"\")\n",
    "    dest_db = \"\\\\\\\\cam-vpnap-nas1\\\\nSpec\\\\Custom Databases\\\\prr_defect_statistics.db\"\n",
    "    table_name = \"PRR_DEFECTS\"\n",
    "    sync_inst = FolderSync(folderpaths, log_path, True)\n",
    "    sync_inst.perform_sync(True, sql_query, dest_db, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610ac990-eff5-43ff-b30f-5824c5c18fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbInterface:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "    def fetch_from(self, query):\n",
    "        engine = create_engine('sqlite:///' + self.filepath.replace('\\\\', '/').rstrip())\n",
    "        conn = engine.connect()\n",
    "        try:\n",
    "            df_fetch = pd.read_sql(query, conn)\n",
    "            if len(df_fetch) > 0:\n",
    "                print(\"Data succesfully fetched\")\n",
    "                return df_fetch\n",
    "            else:\n",
    "                print(\"Database file returns empty list from query\")\n",
    "                return df_fetch\n",
    "        except:\n",
    "            print('Database file not in correct format, returning empty dataframe')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def append_to(self, dataframe, table_name):\n",
    "        engine = create_engine('sqlite:///' + self.filepath.replace('\\\\', '/').rstrip())\n",
    "        try:\n",
    "            df.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "            print(\"Successfully appended data to database connection\")\n",
    "        except Exception as e:\n",
    "            print(f\"Data appending failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383ab4a-272c-4df2-9ed3-cc230929c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this query we use sqlalchemy instead of sqlite3\n",
    "# this is to allow the use of sqlalchemy's TextClause object for more readable sql query formatting within the code\n",
    "# additionally, we include the ScanProperties table twice to select both the SampleID and JobName\n",
    "\n",
    "process = subprocess.Popen([\"dir\", \"\\\\\\\\cam-vpnap-nas1\\\\nSpec\\\\Scans\\\\*.db\", \"/b\", \"/s\"], \n",
    "\tstdout=subprocess.PIPE, stderr=subprocess.PIPE, shell = True, text=True)\n",
    "\n",
    "df_sql_query = pd.DataFrame()\n",
    "\n",
    "for line in process.stdout:\n",
    "    print(\"Current database filepath: \", line.rstrip())\n",
    "    engine = create_engine('sqlite:///' + line.replace('\\\\', '/').rstrip())\n",
    "    conn = engine.connect()\n",
    "    sql_cmd_new_style = text(\"\"\"\n",
    "    SELECT vwDefects.DefectID, \n",
    "           vwDefects.ImageID, \n",
    "           vwDefects.AnalysisID, \n",
    "           vwDefects.DeviceID, \n",
    "           vwDefects.X, \n",
    "           vwDefects.Y, \n",
    "           vwDefects.W, \n",
    "           vwDefects.H, \n",
    "           vwDefects.Area, \n",
    "           vwDefects.Intensity, \n",
    "           vwDefects.IntensityDeviation, \n",
    "           vwDefects.Eccentricity, \n",
    "           vwDefects.Orientation, \n",
    "           vwDefects.XinDevice, \n",
    "           vwDefects.YinDevice, \n",
    "           vwDefects.ClassID, \n",
    "           vwDefects.Score, \n",
    "           vwDefects.Contour, \n",
    "           vwDefects.ClassName, \n",
    "           ParameterGroups.Name, \n",
    "           SPA.PropertyData AS SampleID,\n",
    "           SPB.PropertyData AS JobName\n",
    "       \n",
    "      FROM vwDefects \n",
    "           INNER JOIN Analysis \n",
    "           ON vwDefects.AnalysisID = Analysis.AnalysisID \n",
    "       \n",
    "           INNER JOIN ScanProperties SPA \n",
    "           ON Analysis.ScanID = SPA.ScanID \n",
    "       \n",
    "           INNER JOIN ScanProperties SPB \n",
    "           ON Analysis.ScanID = SPB.ScanID\n",
    "       \n",
    "           INNER JOIN ParameterGroups \n",
    "           ON Analysis.ParameterGroupGUID = ParameterGroups.GroupGUID \n",
    "       \n",
    "     WHERE ParameterGroups.Name = '5XBF_BareWaferPRR' \n",
    "       AND SPA.PropertyName = 'SampleID'\n",
    "       AND SPB.PropertyName = 'JobName'\n",
    "    \"\"\")\n",
    "    try:\n",
    "        df_fetch = pd.read_sql(sql_cmd_new_style, conn)\n",
    "        if len(df_fetch) > 0:\n",
    "            df_sql_query = pd.concat([df_sql_query, df_fetch], ignore_index = True)\n",
    "            print(\"Data succesfully fetched\")\n",
    "        else:\n",
    "            print(\"Database file returns empty list from query\")\n",
    "    except:\n",
    "        print('Database file not in correct format')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
